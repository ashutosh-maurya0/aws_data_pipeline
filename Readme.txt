Team3_Presentation.pdf

Presentation is intended for stakeholders, team members, and anyone interested in the development process and outcomes of the AWS Automated Data Pipeline project. It provides insights into the project's technical challenges, solutions, and the collaborative efforts.


Team3_Technical_Design_Document.pdf

This document outlines the technical specifications, design configurations, and two primary approaches for implementing an automated data pipeline involving AWS services and Google BigQuery. It includes detailed configurations, architectural designs, and step-by-step implementation guides for each approach.

Note: Google BigQuery part was not implemented due to access issue(Google to me no credit card lol ): ). 


Team3_Review_Document.pdf

A detailed review of the AWS Automated Data Pipeline project's iterative development. It assesses methods ranging from hardcoded schemas to dynamic schema discovery and processing, focusing on enhancing adaptability, efficiency, and scalability of data pipelines.


Team3_Unit_Test_Document.pdf

This document presents a structured approach for conducting unit tests on the AWS Automated Data Pipeline project, specifically focusing on AWS EMR and AWS Glue implementations. It includes test scenarios, expected outcomes, and a summary of issues faced along with their resolutions.


Team3_Datat_Set

This folder contains all the data (in CSV format) utilized for testing purposes throughout the project. We employed two distinct datasets during the development process, both pertaining to employee information.

Important Note: The dataset used for the AWS Glue solution segment of our project exceeds the size limits for inclusion in this zip file. To access this extensive dataset, please follow the link provided below:

[Link to the AWS Glue Solution Dataset]
https://drive.google.com/drive/folders/1Lhauar8xiQBogI-xtwL7e7MF3JNV5Et6?usp=sharing)


Team3_EMR_PySpark_Solution

This folder contains all the source code relevant to the EMR and PySpark solutions developed for the AWS Automated Data Pipeline project. Within, you will find three distinct iterations aimed at merging new data with existing datasets effectively. Each iteration represents a phase of development and testing, reflecting progressive improvements in handling and processing data.


Team3_Glue_Solution

This directory encapsulates all the code pertinent to the Glue solution devised for the AWS Automated Data Pipeline project. It encompasses a variety of files, each serving distinct functions within the solution’s architecture. The purpose of these files ranges from data normalization and merging to cleaning and grouping, all integral to the sophisticated handling of datasets during the project.

Usage:

1- Review the Technical Design Document for a comprehensive understanding of the project's technical foundation and implementation strategies.
2- Consult the Review Document for insights into the design and code review process, including identified strengths and suggested improvements.
3- Refer to the Unit Test Document for detailed testing procedures, scenarios, and outcomes critical for evaluating the project's iterations.
